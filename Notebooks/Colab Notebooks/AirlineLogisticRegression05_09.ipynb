{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Connect to TPU\n",
        "tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "tf.config.experimental_connect_to_cluster(tpu)\n",
        "tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "strategy = tf.distribute.TPUStrategy(tpu)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jgE2-RrA8Ii9",
        "outputId": "47a65bb4-d7fe-4f9b-aa3d-4d3b89ea0d00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.105.90.2:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ts-UYkpo7PHy"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from google.colab import drive\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Connecting to Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Load the preprocessed and balanced features from CSV\n",
        "df_resampled_features = pd.read_csv('/content/drive/MyDrive/yuksekTez/airline_dataset/preprocessed_balanced_features.csv')\n",
        "\n",
        "# Load the balanced labels from CSV\n",
        "df_resampled_labels = pd.read_csv('/content/drive/MyDrive/yuksekTez/airline_dataset/preprocessed_balanced_labels.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0wcQyZtk8MRG",
        "outputId": "2f23b94b-4084-48c3-b995-a2996f84d576"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with strategy.scope():\n",
        "    # Create the feature matrix (X) and target vector (y)\n",
        "    X = df_resampled_features.values\n",
        "    y = df_resampled_labels['airline_sentiment'].values\n",
        "\n",
        "    # Split the data into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
        "\n",
        "    # Train a logistic regression model\n",
        "    model = LogisticRegression(solver='liblinear')\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Test the model on the test set\n",
        "    y_pred = model.predict(X_test)"
      ],
      "metadata": {
        "id": "-IVkw-RW8Px1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the accuracy of the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print('Accuracy:', accuracy)\n",
        "\n",
        "# Calculate and print additional metrics\n",
        "print('Classification Report:\\n', classification_report(y_test, y_pred))\n",
        "print('Confusion Matrix:\\n', confusion_matrix(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gloyieTj8V8T",
        "outputId": "f51953a8-7c27-4bbc-d5ea-b0b4e9e8c61f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8083962812318419\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.88      0.81      0.84      2374\n",
            "     neutral       0.70      0.85      0.77      2233\n",
            "    positive       0.87      0.77      0.82      2277\n",
            "\n",
            "    accuracy                           0.81      6884\n",
            "   macro avg       0.82      0.81      0.81      6884\n",
            "weighted avg       0.82      0.81      0.81      6884\n",
            "\n",
            "Confusion Matrix:\n",
            " [[1912  347  115]\n",
            " [ 204 1889  140]\n",
            " [  68  445 1764]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Load the preprocessed and balanced dataset\n",
        "# Load the preprocessed and balanced dataset\n",
        "X = df_resampled_features.values\n",
        "y = df_resampled_labels['airline_sentiment'].values\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
        "\n",
        "# Define a hyperparameter grid for tuning\n",
        "param_grid = {\n",
        "    'C': [0.001, 0.01, 0.1, 1, 10, 100],  # Adjust as needed\n",
        "    'penalty': ['l1', 'l2']  # Adjust as needed\n",
        "}\n",
        "\n",
        "# Perform hyperparameter tuning using GridSearchCV\n",
        "grid_search = GridSearchCV(LogisticRegression(solver='liblinear'), param_grid, cv=5, scoring='accuracy')\n",
        "grid_search.fit(X_train, y_train)\n",
        "best_params = grid_search.best_params_\n",
        "best_lr_model = grid_search.best_estimator_\n",
        "\n",
        "# Train the best Logistic Regression model\n",
        "best_lr_model.fit(X_train, y_train)\n",
        "y_pred = best_lr_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "# Print the best hyperparameters found by GridSearchCV\n",
        "print(\"Best Hyperparameters:\", best_params)\n",
        "\n",
        "# Print classification report and confusion matrix\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gczwKgC8-TrU",
        "outputId": "b0b884fa-18d1-44f8-9afd-b69a77a30206"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8654851830331203\n",
            "Best Hyperparameters: {'C': 100, 'penalty': 'l1'}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.93      0.75      0.83      2374\n",
            "     neutral       0.80      0.92      0.85      2233\n",
            "    positive       0.89      0.93      0.91      2277\n",
            "\n",
            "    accuracy                           0.87      6884\n",
            "   macro avg       0.87      0.87      0.86      6884\n",
            "weighted avg       0.87      0.87      0.86      6884\n",
            "\n",
            "Confusion Matrix:\n",
            " [[1782  397  195]\n",
            " [ 108 2055   70]\n",
            " [  25  131 2121]]\n"
          ]
        }
      ]
    }
  ]
}