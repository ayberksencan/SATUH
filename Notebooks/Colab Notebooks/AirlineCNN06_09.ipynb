{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sFELTC-dXCVi"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "# Connect to TPU\n",
        "tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "tf.config.experimental_connect_to_cluster(tpu)\n",
        "tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "strategy = tf.distribute.TPUStrategy(tpu)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense, Dropout, MaxPooling1D\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from google.colab import drive"
      ],
      "metadata": {
        "id": "a7_E9Hy9XNIT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Connect to Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Load the preprocessed and balanced dataset\n",
        "df_features = pd.read_csv('/content/drive/MyDrive/yuksekTez/airline_dataset/preprocessed_balanced_features.csv')\n",
        "df_labels = pd.read_csv('/content/drive/MyDrive/yuksekTez/airline_dataset/preprocessed_balanced_labels.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HExjJstaXm3e",
        "outputId": "b73a64a5-fceb-43f8-be32-2c7b89369605"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = df_features.values\n",
        "y = df_labels['airline_sentiment'].values\n",
        "\n",
        "# Split the dataset into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
        "input_dim = X_train.shape[1]"
      ],
      "metadata": {
        "id": "YzC8HzxlX09u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
        "# Create a simple CNN model\n",
        "with strategy.scope():\n",
        "    model = keras.Sequential([\n",
        "        tf.keras.layers.Embedding(input_dim=input_dim, output_dim=64, input_length=X_train.shape[1]),\n",
        "        tf.keras.layers.Conv1D(filters=64, kernel_size=3, padding=\"same\", activation=\"relu\"),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.GlobalMaxPooling1D(),\n",
        "        tf.keras.layers.Dropout(0.5),\n",
        "        tf.keras.layers.Dense(units=64, activation=\"relu\", kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
        "        tf.keras.layers.Dropout(0.5),\n",
        "        tf.keras.layers.Dense(units=3, activation=\"softmax\")\n",
        "    ])\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Print the model summary\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vJ_UrLoVX5IC",
        "outputId": "87de52f8-3116-4c27-fda2-ae203e0833a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 12434, 64)         795776    \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 12434, 64)         12352     \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 12434, 64)        256       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " global_max_pooling1d (Globa  (None, 64)               0         \n",
            " lMaxPooling1D)                                                  \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 64)                0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 64)                4160      \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 3)                 195       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 812,739\n",
            "Trainable params: 812,611\n",
            "Non-trainable params: 128\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Initialize the label encoder\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# Encode your string labels into integers\n",
        "y_train_encoded = label_encoder.fit_transform(y_train)\n",
        "y_test_encoded = label_encoder.transform(y_test)\n",
        "\n",
        "# Convert your data to TensorFlow tensors\n",
        "X_train_tensor = tf.convert_to_tensor(X_train, dtype=tf.float32)\n",
        "y_train_tensor = tf.convert_to_tensor(y_train_encoded, dtype=tf.int32)\n",
        "X_test_tensor = tf.convert_to_tensor(X_test, dtype=tf.float32)\n",
        "y_test_tensor = tf.convert_to_tensor(y_test_encoded, dtype=tf.int32)\n",
        "\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Define early stopping callback\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)"
      ],
      "metadata": {
        "id": "CcNhehjRX7kK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model using TensorFlow tensors and include early stopping\n",
        "with strategy.scope():\n",
        "    history = model.fit(X_train_tensor, y_train_tensor,\n",
        "              epochs=100,\n",
        "              batch_size=32,\n",
        "              validation_data=(X_test_tensor, y_test_tensor),\n",
        "              callbacks=[early_stopping])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Amd1EzKhkueO",
        "outputId": "0bbb1963-a610-48b0-8128-a59e85e623c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "646/646 [==============================] - 28s 33ms/step - loss: 1.1284 - accuracy: 0.3403 - val_loss: 1.1142 - val_accuracy: 0.3308\n",
            "Epoch 2/100\n",
            "646/646 [==============================] - 13s 21ms/step - loss: 1.1048 - accuracy: 0.3391 - val_loss: 1.0990 - val_accuracy: 0.3300\n",
            "Epoch 3/100\n",
            "646/646 [==============================] - 13s 20ms/step - loss: 1.0987 - accuracy: 0.3409 - val_loss: 1.0998 - val_accuracy: 0.3308\n",
            "Epoch 4/100\n",
            "646/646 [==============================] - 13s 20ms/step - loss: 1.0970 - accuracy: 0.3419 - val_loss: 1.1736 - val_accuracy: 0.3308\n",
            "Epoch 5/100\n",
            "646/646 [==============================] - 13s 21ms/step - loss: 1.0961 - accuracy: 0.3398 - val_loss: 1.0964 - val_accuracy: 0.3308\n",
            "Epoch 6/100\n",
            "646/646 [==============================] - 13s 20ms/step - loss: 1.0958 - accuracy: 0.3405 - val_loss: 1.0954 - val_accuracy: 0.3300\n",
            "Epoch 7/100\n",
            "646/646 [==============================] - 13s 20ms/step - loss: 1.0951 - accuracy: 0.3376 - val_loss: 1.0934 - val_accuracy: 0.3598\n",
            "Epoch 8/100\n",
            "646/646 [==============================] - 13s 20ms/step - loss: 1.0951 - accuracy: 0.3407 - val_loss: 1.0925 - val_accuracy: 0.3598\n",
            "Epoch 9/100\n",
            "646/646 [==============================] - 13s 20ms/step - loss: 1.0956 - accuracy: 0.3388 - val_loss: 1.0961 - val_accuracy: 0.3308\n",
            "Epoch 10/100\n",
            "646/646 [==============================] - 13s 19ms/step - loss: 1.0946 - accuracy: 0.3391 - val_loss: 1.0959 - val_accuracy: 0.3300\n",
            "Epoch 11/100\n",
            "646/646 [==============================] - 13s 20ms/step - loss: 1.0957 - accuracy: 0.3429 - val_loss: 1.0928 - val_accuracy: 0.3300\n",
            "Epoch 12/100\n",
            "646/646 [==============================] - 13s 20ms/step - loss: 1.0950 - accuracy: 0.3404 - val_loss: 1.0925 - val_accuracy: 0.3598\n",
            "Epoch 13/100\n",
            "646/646 [==============================] - 13s 20ms/step - loss: 1.0945 - accuracy: 0.3429 - val_loss: 1.0937 - val_accuracy: 0.3300\n",
            "Epoch 14/100\n",
            "646/646 [==============================] - 13s 20ms/step - loss: 1.0954 - accuracy: 0.3410 - val_loss: 1.0994 - val_accuracy: 0.3300\n",
            "Epoch 15/100\n",
            "646/646 [==============================] - 13s 20ms/step - loss: 1.0946 - accuracy: 0.3425 - val_loss: 1.0924 - val_accuracy: 0.3598\n",
            "Epoch 16/100\n",
            "646/646 [==============================] - 13s 19ms/step - loss: 1.0951 - accuracy: 0.3420 - val_loss: 1.0938 - val_accuracy: 0.3300\n",
            "Epoch 17/100\n",
            "646/646 [==============================] - 13s 20ms/step - loss: 1.0951 - accuracy: 0.3432 - val_loss: 1.0948 - val_accuracy: 0.3300\n",
            "Epoch 18/100\n",
            "646/646 [==============================] - 13s 20ms/step - loss: 1.0948 - accuracy: 0.3375 - val_loss: 1.0935 - val_accuracy: 0.3300\n",
            "Epoch 19/100\n",
            "646/646 [==============================] - 13s 20ms/step - loss: 1.0945 - accuracy: 0.3392 - val_loss: 1.0924 - val_accuracy: 0.3598\n",
            "Epoch 20/100\n",
            "646/646 [==============================] - 13s 20ms/step - loss: 1.0950 - accuracy: 0.3418 - val_loss: 1.0938 - val_accuracy: 0.3300\n",
            "Epoch 21/100\n",
            "646/646 [==============================] - 14s 21ms/step - loss: 1.0945 - accuracy: 0.3450 - val_loss: 1.0928 - val_accuracy: 0.3300\n",
            "Epoch 22/100\n",
            "646/646 [==============================] - 13s 20ms/step - loss: 1.0947 - accuracy: 0.3422 - val_loss: 1.0932 - val_accuracy: 0.3300\n",
            "Epoch 23/100\n",
            "646/646 [==============================] - 13s 20ms/step - loss: 1.0952 - accuracy: 0.3424 - val_loss: 1.0963 - val_accuracy: 0.3300\n",
            "Epoch 24/100\n",
            "646/646 [==============================] - 13s 20ms/step - loss: 1.0953 - accuracy: 0.3435 - val_loss: 1.0960 - val_accuracy: 0.3308\n",
            "Epoch 25/100\n",
            "646/646 [==============================] - 13s 20ms/step - loss: 1.0945 - accuracy: 0.3427 - val_loss: 1.0938 - val_accuracy: 0.3598\n",
            "Epoch 26/100\n",
            "646/646 [==============================] - 13s 20ms/step - loss: 1.0945 - accuracy: 0.3402 - val_loss: 1.0929 - val_accuracy: 0.3300\n",
            "Epoch 27/100\n",
            "646/646 [==============================] - 13s 20ms/step - loss: 1.0949 - accuracy: 0.3407 - val_loss: 1.0944 - val_accuracy: 0.3308\n",
            "Epoch 28/100\n",
            "646/646 [==============================] - 13s 20ms/step - loss: 1.0945 - accuracy: 0.3399 - val_loss: 1.0926 - val_accuracy: 0.3598\n",
            "Epoch 29/100\n",
            "646/646 [==============================] - 13s 21ms/step - loss: 1.0946 - accuracy: 0.3387 - val_loss: 1.0936 - val_accuracy: 0.3300\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test_tensor, y_test_tensor)\n",
        "print('Test accuracy:', accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LYG1UjpDmyqJ",
        "outputId": "25dc5411-cc79-4f8e-cebc-d147a60def87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "216/216 [==============================] - 3s 13ms/step - loss: 1.0924 - accuracy: 0.3598\n",
            "Test accuracy: 0.35981985926628113\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# After training the model, you can make predictions\n",
        "y_pred_probs = model.predict(X_test_tensor)\n",
        "\n",
        "# Convert predicted probabilities to class labels\n",
        "y_pred_labels = np.argmax(y_pred_probs, axis=1)\n",
        "\n",
        "# Define the class names corresponding to your sentiment classes\n",
        "class_names = [\"negative\", \"neutral\", \"positive\"]\n",
        "\n",
        "# Generate the classification report\n",
        "classification_report_str = classification_report(y_test_tensor, y_pred_labels, target_names=class_names)\n",
        "print('Classification Report:\\n', classification_report_str)\n",
        "\n",
        "# Generate the confusion matrix\n",
        "confusion_mat = confusion_matrix(y_test, y_pred_labels)\n",
        "\n",
        "# Print or plot the confusion matrix as needed\n",
        "print('Confusion Matrix:\\n', confusion_mat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 723
        },
        "id": "rsOBBSSvbWyf",
        "outputId": "d46d318d-816e-422b-9cda-9917ced7513b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "216/216 [==============================] - 2s 8ms/step\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.35      0.99      0.52      2374\n",
            "     neutral       0.00      0.00      0.00      2233\n",
            "    positive       0.55      0.05      0.10      2277\n",
            "\n",
            "    accuracy                           0.36      6884\n",
            "   macro avg       0.30      0.35      0.21      6884\n",
            "weighted avg       0.30      0.36      0.21      6884\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-0c70221a3503>\u001b[0m in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# Generate the confusion matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mconfusion_mat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# Print or plot the confusion matrix as needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mconfusion_matrix\u001b[0;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[1;32m    320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 322\u001b[0;31m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munique_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    323\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36munique_labels\u001b[0;34m(*ys)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;31m# Check that we don't mix string type with number type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mys_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Mix of label input types (string and number)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mys_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Mix of label input types (string and number)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_learning_curve(history):\n",
        "    # Plot training & validation accuracy values\n",
        "    plt.plot(history.history['accuracy'])\n",
        "    plt.plot(history.history['val_accuracy'])\n",
        "    plt.title('Model accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "    plt.show()\n",
        "\n",
        "    # Plot training & validation loss values\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.title('Model loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "    plt.show()\n",
        "\n",
        "# Assuming 'history' is the variable storing your model's training history\n",
        "plot_learning_curve(history)"
      ],
      "metadata": {
        "id": "rrlTa6B_FMNa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}